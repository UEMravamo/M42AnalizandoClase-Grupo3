{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "778f09d4-6d95-4850-8017-dd77e151d5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytest in c:\\users\\ruben\\anaconda3\\lib\\site-packages (7.4.4)\n",
      "Requirement already satisfied: pyspark in c:\\users\\ruben\\anaconda3\\lib\\site-packages (3.5.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\ruben\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\ruben\\anaconda3\\lib\\site-packages (0.14.2)\n",
      "Requirement already satisfied: pmdarima in c:\\users\\ruben\\anaconda3\\lib\\site-packages (2.0.4)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from pytest) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\ruben\\appdata\\roaming\\python\\python312\\site-packages (from pytest) (24.2)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from pytest) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ruben\\appdata\\roaming\\python\\python312\\site-packages (from pytest) (0.4.6)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ruben\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from statsmodels) (1.13.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from pmdarima) (1.4.2)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from pmdarima) (3.0.11)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from pmdarima) (1.5.1)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from pmdarima) (2.2.3)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from pmdarima) (75.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\ruben\\appdata\\roaming\\python\\python312\\site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ruben\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->pmdarima) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytest pyspark pandas statsmodels pmdarima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04c70cce-8ae6-4da1-93af-8bed729bc24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "# Ignorar advertencias generales\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Ignorar advertencias de statsmodels específicas\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"A date index has been provided, but it has no associated frequency information\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"No supported index is available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2528b00-87f3-407b-b763-f77505544d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando test con el CSV 'asistencia_clase_modificada.csv'...\n",
      "Procesando asignatura: Grandes Volumenes de Datos\n",
      "Resultados para Grandes Volumenes de Datos: {'presentes': 10, 'tarde': 6, 'ausentes': 4}\n",
      "Procesando asignatura: Administracion de Sistemas\n",
      "Resultados para Administracion de Sistemas: {'presentes': 10, 'tarde': 6, 'ausentes': 4}\n",
      "Procesando asignatura: Ingenieria del Software\n",
      "Resultados para Ingenieria del Software: {'presentes': 10, 'tarde': 6, 'ausentes': 4}\n",
      "Procesando asignatura: Empresa y Legislacion\n",
      "Resultados para Empresa y Legislacion: {'presentes': 10, 'tarde': 6, 'ausentes': 4}\n",
      "Procesando asignatura: None\n",
      "Resultados para None: {'presentes': 0, 'tarde': 0, 'ausentes': 0}\n",
      "Resultados Globales del Forecast: {'Grandes Volumenes de Datos': {'presentes': 10, 'tarde': 6, 'ausentes': 4}, 'Administracion de Sistemas': {'presentes': 10, 'tarde': 6, 'ausentes': 4}, 'Ingenieria del Software': {'presentes': 10, 'tarde': 6, 'ausentes': 4}, 'Empresa y Legislacion': {'presentes': 10, 'tarde': 6, 'ausentes': 4}, None: {'presentes': 0, 'tarde': 0, 'ausentes': 0}}\n",
      "Test completado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, date_format, count\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "# Configuro las rutas de Python necesarias para que Spark funcione correctamente\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"C:\\\\Users\\\\ruben\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"C:\\\\Users\\\\ruben\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe\"\n",
    "\n",
    "# Creo la sesión de Spark para poder trabajar con los datos\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestForecastWithCSV\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "\n",
    "# Función que se encarga de generar el forecast, NO LA MODIFICO\n",
    "def generar_forecast_por_asignatura(data):\n",
    "    # Transformo la columna de timestamp para extraer solo la fecha\n",
    "    data = data.withColumn(\"fecha\", date_format(col(\"timestamp\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "    # Agrupo los datos por estado de asistencia y fecha, y calculo totales diarios\n",
    "    totales_diarios = data.groupBy(\"estado_asistencia\", \"fecha\").agg(count(\"alumno\").alias(\"total_diario\"))\n",
    "    totales_pandas = totales_diarios.toPandas()\n",
    "    totales_pandas[\"fecha\"] = pd.to_datetime(totales_pandas[\"fecha\"])\n",
    "    totales_pandas = totales_pandas.sort_values(by=[\"estado_asistencia\", \"fecha\"])\n",
    "\n",
    "    # Diccionario para guardar los resultados del forecast\n",
    "    forecast_resultados = {\"presentes\": 0, \"tarde\": 0, \"ausentes\": 0}\n",
    "\n",
    "    # Hago el análisis por cada estado (presente, tarde y ausente)\n",
    "    for estado in [\"presente\", \"tarde\", \"ausente\"]:\n",
    "        grupo_estado = totales_pandas[totales_pandas[\"estado_asistencia\"] == estado]\n",
    "\n",
    "        # Solo hago el forecast si hay más de 10 registros\n",
    "        if len(grupo_estado) > 10:\n",
    "            try:\n",
    "                # Ajusto el modelo ARIMA\n",
    "                serie = grupo_estado.set_index(\"fecha\")[\"total_diario\"]\n",
    "                modelo_auto = auto_arima(serie, seasonal=False, stepwise=True, trace=False)\n",
    "                modelo = ARIMA(serie, order=modelo_auto.order)\n",
    "                ajuste = modelo.fit()\n",
    "                prediccion = ajuste.forecast(steps=1)\n",
    "\n",
    "                # Actualizo el diccionario con el valor predicho\n",
    "                if estado == \"presente\":\n",
    "                    forecast_resultados[\"presentes\"] = round(prediccion.iloc[0])\n",
    "                elif estado == \"tarde\":\n",
    "                    forecast_resultados[\"tarde\"] = round(prediccion.iloc[0])\n",
    "                elif estado == \"ausente\":\n",
    "                    forecast_resultados[\"ausentes\"] = round(prediccion.iloc[0])\n",
    "            except Exception as e:\n",
    "                print(f\"Error al ajustar ARIMA para {estado}: {str(e)}\")\n",
    "\n",
    "    return forecast_resultados\n",
    "\n",
    "# Cargo el archivo CSV con los datos\n",
    "df = spark.read.csv(\"C:/Users/ruben/Downloads/Bigggg/asistencia_clase_modificada.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Elimino los duplicados para asegurar que cada alumno esté solo una vez en cada clase\n",
    "df = df.dropDuplicates(subset=[\"timestamp\", \"asignatura\", \"alumno\"])\n",
    "\n",
    "# Agrego una columna con solo la fecha para poder agrupar correctamente\n",
    "df = df.withColumn(\"fecha\", date_format(col(\"timestamp\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Obtengo todas las asignaturas del dataset para analizarlas una por una\n",
    "asignaturas = [row[\"asignatura\"] for row in df.select(\"asignatura\").distinct().collect()]\n",
    "\n",
    "# Creo la función de test para procesar los datos y verificar el forecast\n",
    "def test_generar_forecast_con_csv():\n",
    "    print(\"Iniciando test con el CSV 'asistencia_clase_modificada.csv'...\")\n",
    "\n",
    "    # Diccionario para guardar los resultados del forecast de todas las asignaturas\n",
    "    resultados_globales = {}\n",
    "\n",
    "    # Proceso los datos por asignatura\n",
    "    for asignatura in asignaturas:\n",
    "        print(f\"Procesando asignatura: {asignatura}\")\n",
    "\n",
    "        # Filtro los datos de la asignatura actual\n",
    "        df_asignatura = df.filter(col(\"asignatura\") == asignatura)\n",
    "\n",
    "        # Llamo a la función de forecast para estos datos\n",
    "        resultados = generar_forecast_por_asignatura(df_asignatura)\n",
    "\n",
    "        # Guardo los resultados en el diccionario\n",
    "        resultados_globales[asignatura] = resultados\n",
    "        print(f\"Resultados para {asignatura}: {resultados}\")\n",
    "\n",
    "    # Imprimo todos los resultados obtenidos\n",
    "    print(\"Resultados Globales del Forecast:\", resultados_globales)\n",
    "\n",
    "    # Hago algunas validaciones básicas para asegurar que el forecast sea correcto\n",
    "    for asignatura, resultados in resultados_globales.items():\n",
    "        assert isinstance(resultados, dict), f\"El resultado para {asignatura} debe ser un diccionario\"\n",
    "        assert \"presentes\" in resultados, f\"Debe contener la clave 'presentes' para {asignatura}\"\n",
    "        assert \"tarde\" in resultados, f\"Debe contener la clave 'tarde' para {asignatura}\"\n",
    "        assert \"ausentes\" in resultados, f\"Debe contener la clave 'ausentes' para {asignatura}\"\n",
    "        assert resultados[\"presentes\"] >= 0, f\"El valor de 'presentes' no puede ser negativo para {asignatura}\"\n",
    "        assert resultados[\"tarde\"] >= 0, f\"El valor de 'tarde' no puede ser negativo para {asignatura}\"\n",
    "        assert resultados[\"ausentes\"] >= 0, f\"El valor de 'ausentes' no puede ser negativo para {asignatura}\"\n",
    "\n",
    "    print(\"Test completado exitosamente.\")\n",
    "\n",
    "# Llamo a la función de test para ejecutar todo\n",
    "test_generar_forecast_con_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "25fa5074-c332-44c8-9645-a85b8fa35237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando test con el CSV 'asistencia_clase_modificada.csv'...\n",
      "Eliminando registros con asignaturas nulas o vacías...\n",
      "Total de registros válidos después del filtrado: 9897\n",
      "Asignaturas únicas detectadas: ['Grandes Volumenes de Datos', 'Administracion de Sistemas', 'Ingenieria del Software', 'Empresa y Legislacion']\n",
      "Procesando cada asignatura por separado...\n",
      "Procesando asignatura: Grandes Volumenes de Datos\n",
      "Total de registros para Grandes Volumenes de Datos: 2438\n",
      "Resultados para Grandes Volumenes de Datos: {'presentes': 10, 'tarde': 6, 'ausentes': 4}\n",
      "Procesando asignatura: Administracion de Sistemas\n",
      "Total de registros para Administracion de Sistemas: 2539\n",
      "Resultados para Administracion de Sistemas: {'presentes': 10, 'tarde': 6, 'ausentes': 4}\n",
      "Procesando asignatura: Ingenieria del Software\n",
      "Total de registros para Ingenieria del Software: 2480\n",
      "Resultados para Ingenieria del Software: {'presentes': 10, 'tarde': 6, 'ausentes': 4}\n",
      "Procesando asignatura: Empresa y Legislacion\n",
      "Total de registros para Empresa y Legislacion: 2440\n",
      "Resultados para Empresa y Legislacion: {'presentes': 10, 'tarde': 6, 'ausentes': 4}\n",
      "Validando los resultados globales...\n",
      "Resultados Globales del Forecast: {'Grandes Volumenes de Datos': {'presentes': 10, 'tarde': 6, 'ausentes': 4}, 'Administracion de Sistemas': {'presentes': 10, 'tarde': 6, 'ausentes': 4}, 'Ingenieria del Software': {'presentes': 10, 'tarde': 6, 'ausentes': 4}, 'Empresa y Legislacion': {'presentes': 10, 'tarde': 6, 'ausentes': 4}}\n",
      "Test completado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "def test_generar_forecast_con_csv():\n",
    "    print(\"Iniciando test con el CSV 'asistencia_clase_modificada.csv'...\")\n",
    "\n",
    "    # Paso 1: Filtrar registros con asignaturas nulas o vacías\n",
    "    print(\"Eliminando registros con asignaturas nulas o vacías...\")\n",
    "    df_filtrado = df.filter((col(\"asignatura\").isNotNull()) & (col(\"asignatura\") != \"\"))\n",
    "\n",
    "    # Validar si hay registros después de filtrar\n",
    "    total_registros = df_filtrado.count()\n",
    "    print(f\"Total de registros válidos después del filtrado: {total_registros}\")\n",
    "    assert total_registros > 0, \"No hay registros válidos en el archivo después del filtrado.\"\n",
    "\n",
    "    # Paso 2: Obtener asignaturas únicas\n",
    "    asignaturas = [row[\"asignatura\"] for row in df_filtrado.select(\"asignatura\").distinct().collect()]\n",
    "    print(f\"Asignaturas únicas detectadas: {asignaturas}\")\n",
    "    assert len(asignaturas) > 0, \"El archivo debe tener asignaturas válidas.\"\n",
    "\n",
    "    # Paso 3: Procesar cada asignatura por separado\n",
    "    print(\"Procesando cada asignatura por separado...\")\n",
    "    resultados_globales = {}\n",
    "\n",
    "    for asignatura in asignaturas:\n",
    "        print(f\"Procesando asignatura: {asignatura}\")\n",
    "\n",
    "        # Filtro los datos por asignatura actual\n",
    "        df_asignatura = df_filtrado.filter(col(\"asignatura\") == asignatura)\n",
    "\n",
    "        # Validar que hay datos suficientes para procesar\n",
    "        registros_asignatura = df_asignatura.count()\n",
    "        print(f\"Total de registros para {asignatura}: {registros_asignatura}\")\n",
    "        assert registros_asignatura > 0, f\"No hay registros para la asignatura {asignatura}.\"\n",
    "\n",
    "        # Ejecutar forecast para esta asignatura\n",
    "        resultados = generar_forecast_por_asignatura(df_asignatura)\n",
    "\n",
    "        # Guardar resultados en el diccionario global\n",
    "        resultados_globales[asignatura] = resultados\n",
    "        print(f\"Resultados para {asignatura}: {resultados}\")\n",
    "\n",
    "    # Paso 4: Validar los resultados globales\n",
    "    print(\"Validando los resultados globales...\")\n",
    "    for asignatura, resultados in resultados_globales.items():\n",
    "        assert isinstance(resultados, dict), f\"El resultado para {asignatura} debe ser un diccionario\"\n",
    "        assert \"presentes\" in resultados, f\"Debe contener la clave 'presentes' para {asignatura}\"\n",
    "        assert \"tarde\" in resultados, f\"Debe contener la clave 'tarde' para {asignatura}\"\n",
    "        assert \"ausentes\" in resultados, f\"Debe contener la clave 'ausentes' para {asignatura}\"\n",
    "        assert resultados[\"presentes\"] >= 0, f\"El valor de 'presentes' no puede ser negativo para {asignatura}\"\n",
    "        assert resultados[\"tarde\"] >= 0, f\"El valor de 'tarde' no puede ser negativo para {asignatura}\"\n",
    "        assert resultados[\"ausentes\"] >= 0, f\"El valor de 'ausentes' no puede ser negativo para {asignatura}\"\n",
    "\n",
    "    # Resultados finales\n",
    "    print(\"Resultados Globales del Forecast:\", resultados_globales)\n",
    "    print(\"Test completado exitosamente.\")\n",
    "\n",
    "# Ejecutar el test\n",
    "test_generar_forecast_con_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b822e7-c566-447e-b2ac-e2a426866120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
